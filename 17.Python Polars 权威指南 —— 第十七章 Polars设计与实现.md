

**本章概述**

在本章中，我们将深入探讨Polars的内部工作原理，揭示其成为强大高效的数据操作库的背后机制。在全书中，你可能已经多次看到提到本章的参考内容，以便更全面地了解Polars的功能。在这里，我们将探索Polars背后的技术、优化技巧和设计原则，这些都是Polars高性能的先决条件。此外，我们还会提供一些工具来分析和测试代码，确保你能够最大限度地优化数据处理任务。读完本章后，你将对Polars的快速高效运行背后的工程设计有更深的理解，并能运用这些内部机制来处理自己的数据任务。

<h2 id="rdtQd">Apache Arrow</h2>
Polars高效性的核心在于其内存管理系统，该系统基于Apache Arrow项目构建。

Arrow自称为“一种用于内存分析的跨语言开发平台。” 它定义了一种“用于平面和层次数据的语言无关的列式内存格式，以适应在现代硬件（如CPU和GPU）上高效的分析操作。” Arrow自带了一些优势：

首先，它使用列式格式。列式格式使数据在顺序访问或扫描时相邻，从而优化了连续块数据的大规模读取过程。这种方式可以将数据存储在大块连续的内存中，并顺序读取。

此外，这种连续的列式布局也非常适合矢量化操作。它还允许使用现代的单指令多数据（SIMD）操作，同时对多个数据点执行相同的操作。

为了进一步说明这些优势，我们将引入一个文件柜的比喻，并在图17-1中进行说明。

![图17-1. Arrow内存缓冲区及其计算优势](https://cdn.nlark.com/yuque/0/2024/png/1310472/1729088671920-46e13737-6a36-478a-9fc4-3e1c38680b57.png)

想象一个存放销售档案的文件柜。在行式格式中，文件柜的每个抽屉都包含单个销售的所有数据：销售给谁、销售的商品、价格以及销售日期。如果你总是需要查看每笔销售的所有信息，将这些信息打包在一起是很实用的。

然而，在分析查询中，更常见的是查找销售档案的特定部分。例如，你可能想要一个关于最大5个客户的报告，这样就知道应该向哪些客户投入更多精力。如果文件柜按行式排列，每个抽屉包含一个客户的档案，那么你必须打开每个抽屉，查看客户和每笔销售的总价。

当你将文件柜按列式排列时，每个抽屉包含一种数据类别。这意味着一个抽屉包含所有客户信息，另一个抽屉则包含所有销售价格。

顺序读取意味着可以从抽屉里的第一个文件开始，然后继续查看下一个，直到抽屉的末尾。这加快了速度，因为你不必关闭一个抽屉，再去另一个抽屉打开查找相关文件。通过价格抽屉，你可以确定最大的客户的档案ID。然后，为了知道客户是谁，你可以前往名字抽屉，直到找到匹配档案ID的五个名字。这样只需打开两个抽屉，而不是全部打开，从而节省了大量时间和精力。

由于这种列式格式，Arrow提供了O(1)时间复杂度的随机访问。这意味着无论数据集多大，访问任何数据的时间都保持不变。在我们的文件柜比喻中，这相当于我们知道每一条信息的确切存放位置：不仅知道在哪个抽屉，还知道在抽屉中的具体位置。因此，你不需要在抽屉中翻找直到找到相关数据。对于需要在大型数据集中访问特定数据点的操作，这种性能提升是非常显著的。

Arrow在许多流行语言中都有实现。到目前为止，这些语言包括C/GLib、C++、C#、Go、Java、JavaScript、Julia、MATLAB、Python、R、Ruby和Rust。不同语言的实现程度可能有所不同，例如，Float16数据类型并未在每种语言中实现。

在许多语言中的实现让你可以使用共享的可变数据集，而无需序列化或反序列化。通常，不同语言在内存中表示数据的方式不同。为了在两种语言之间匹配数据，你首先需要将数据从一种格式反序列化，然后再序列化为另一种格式。这种转换过程耗时。而Arrow通过让所有支持的实现和语言能够以统一的方式与相同的数据集通信来避免这个问题。共享可变数据集被称为进程间通信（IPC）。Arrow支持在同一进程中进行零拷贝数据读取，无需序列化/反序列化的开销。你可以在Polars中读取一个文件，然后将其传递给其他支持Arrow的库，如Great Tables、hvPlot或Altair，而无需将其转换为其他格式。



<h2 id="VvK92">多线程计算和SIMD操作</h2>
Polars从一开始就设计为能够利用现代硬件的优势，如支持多线程的多核CPU和可以并行运行数千个简单任务的GPU。这使得能够同时运行多个计算成为可能。

Python有一个全局解释器锁（GIL），它阻止多个线程同时执行Python代码。这简化了实现并使单线程运行更快，但限制了Python对多核的利用。如果一个Python程序执行大量计算，它将只使用CPU的一个核心。为了解决这个问题，Polars的核心是用Rust编写的，Rust没有这个问题（还有其他性能优势，如更快的字节码）。Polars可以并行运行多个计算，充分利用所有可用的核心。

Polars利用多核的一个方式是使用SIMD操作。通过将数据排列在内存中或进行矢量化，具有多个计算核心的计算机可以在多个数据点上同时执行相同的指令。SIMD的起源可以追溯到早期的图形处理，当时常常需要对许多像素同时执行相同的操作。例如，屏幕闪烁会导致所有图像的亮度同时增加。如今，SIMD操作也可以在数据上执行，Polars利用这一点来加速计算。

<h2 id="sqEU5">内存中的字符串数据类型</h2>
在第3章中，我们介绍了字符串数据类型。字符串的一个挑战是其长度不固定。例如，整数是固定长度的，可以通过将整数的大小加到当前内存地址来计算下一个整数的内存地址。而字符串的长度未知，因此无法仅从数据缓冲区中预测下一个字符串的内存地址。这意味着字符串的存储方式不同于整数：它们是连续地存储在数据缓冲区中的。连续内存是一个长的内存块，所有的值按顺序存储。

字符串的视图布局存储了多个属性：

+ **字节0到3**存储字符串的长度。
+ **字节4到7**存储字符串的前四个字节的副本。这提供了“快速路径”或优化，因为这四个字节通常包含快速比较所需的信息。
+ **字节8到11**存储字符串所在数据缓冲区的索引。
+ **字节12到15**存储偏移量，即字符串在数据缓冲区中开始的位置。

有了这些信息，就可以从数据缓冲区中检索字符串，而无需遍历内存！

Polars对长度小于12个字节的字符串进行了进一步优化。在这种情况下，字符串直接存储在视图布局中，而不是数据缓冲区中。这称为内联存储。当字符串长度不超过12个字节时，可以存储在长度之后的12个字节中。这避免了Polars需要分配内存和在数据缓冲区中查找的情况，这些操作代价较高。

图17-2说明了这种存储方式，以Polars开发者喜欢的乐队为例。“Aerosmith”适合内联存储，因此不在数据缓冲区中。而“Toots and the Maytals”则从数据缓冲区中第22个位置（在“The Velvet Underground”之后，第一个位置为0）开始存储。

![图17-2. 短字符串和长字符串在内存中的存储方式](https://cdn.nlark.com/yuque/0/2024/png/1310472/1729089002043-edd360e4-a40f-441e-b1d8-9ab11654902c.png)



在第3章中，我们介绍了Series数据结构。然而，这并不是Polars中最低级的数据结构。每个Series（以及DataFrame中的每一列）在内部都是表示为一个分块数组（ChunkedArray）。

一个`ChunkedArray`是一个数据数组序列的容器类。使用分块数组而不是单个包含所有数据的数组可以实现多种优化，包括优化内存管理。当向`ChunkedArray`添加数据时，数据被添加到现有对象中。这样Polars就不必将数据复制到一个新对象或对旧对象进行垃圾回收，从而节省时间。此外，Polars允许将数据分割成独立的块，并行操作这些块以最大化性能。每个块可以由不同的CPU核心处理，从而显著加快计算速度。

---

**<font style="color:#01B2BC;">注意事项</font>**

管理数据块可以优化Polars处理数据的方式。重分块（rechunking）是指更改`ChunkedArray`的块大小。在Polars中，重分块通常意味着将所有数据放入一个单独的块中。在每个块内，数据在内存中保持连续存储。在贪婪模式下（eager mode），读取后数据会自动重分块。Polars假设在贪婪模式下，用户希望对数据进行分析。通常，同一个数据帧会被多次查询，因此花费额外时间进行重分块是值得的。当使用惰性求值时，查询优化器会决定何时重分块。

通常情况下，重分块并不是需要特别关注的事情，除非是在进行基准测试时。在这种情况下，需要了解的是，当你在某个操作中将`rechunk`参数设置为`True`时，实际上会执行两个操作。

---



<h2 id="l1peC">查询优化</h2>
在第4章中，我们讨论了Polars如何通过惰性API优化查询，但并未深入探讨其工作原理。在本节中，我们将深入了解Polars所使用的一些优化技术，以使查询尽可能快速地执行。

<h3 id="vY7N6">`LazyFrame`扫描级别优化</h3>
第一类优化是针对扫描级别的数据加载。扫描级别是Polars从其数据源读取数据的执行层。这些优化的重点是完全避免读取不会使用的数据。

<h4 id="yvKWA">投影下推</h4>
投影下推（Projection Pushdown）是通过将列选择尽可能向上游移动来优化查询。这可以防止将未使用的列读入内存。

在这个例子中，我们将探索书中使用的出租车数据集。我们仍然会尝试找出每英里收入最高的前三个供应商。不过，这次我们将使用惰性API来完成：

```python
lf = pl.scan_parquet("data/taxi/yellow_tripdata_*.parquet")  # 1
lf.select(pl.col("trip_distance")).show_graph()  # 2
```

1. `scan_parquet()`不会立即从磁盘读取文件，而是返回一个`LazyFrame`，其中只扫描相关的元数据，如模式（schema）和行、列的数量。`LazyFrame`暴露了Polars的惰性API。其可用的方法几乎相同，不同之处在于仅在调用`.collect()`时才会执行。
2. 选择仅`trip_distance`列，并使用`show_graph()`打印查询计划，这样就可以看到查询引擎的执行情况。你会发现，19列中只有1列会被读入内存。

![图17-3. 扫描出租车数据集并选择单列的查询计划](https://cdn.nlark.com/yuque/0/2024/png/1310472/1729089313483-40d0b30b-b61b-44d5-a2f7-6ca30d21fdef.png)

该图展示了查询计划。查询计划是一个树状结构，显示了为获得结果而将执行的步骤。需要一些解释：

1. 第一个执行的步骤是底部的步骤，因此应从下往上阅读查询计划。
2. 每个方框对应查询计划中的一个阶段。在本例中，只有一个步骤，即扫描Parquet文件。在后续的例子中，你会看到更多的步骤。
3. 符号表示选择，指示任何行过滤条件。
4. 符号表示投影，指选择某些列的子集。

在图17-3中可以看到，投影包含从19个可用列中选择了1列。在图17-4中可以看到，选择包含对`trip_distance`列的过滤。

<h4 id="YPJPy">谓词下推</h4>
接下来要介绍的优化是谓词下推（Predicate Pushdown），其工作原理类似于投影下推，但重点是过滤行而不是选择列。这有助于避免读取不需要的行。

示例代码如下：

```python
lf.filter(pl.col("trip_distance") > 10).show_graph()
```

这段代码对`trip_distance`列进行过滤，仅保留大于10的行，并使用`show_graph()`显示查询计划。

![图17-4. 对trip_distance列的值进行过滤后的查询计划](https://cdn.nlark.com/yuque/0/2024/png/1310472/1729089415031-0f0c4140-897b-41a4-83f7-e99d0579662f.png)

上面的代码对`trip_distance`列的值进行过滤，保留大于10的值。在图17-4中，可以看到表示过滤的符号。这种过滤将逐行应用。

<h4 id="QV7Ha">切片下推</h4>
切片下推（Slice Pushdown）在扫描级别（即数据读取到内存的阶段）仅加载所需的数据切片。与谓词下推类似，它可以防止读取未使用的行，但不是根据过滤条件读取行，而是根据行是否属于某个数据块进行读取。可以使用以下命令实现切片下推：

```python
lf.head(2).collect()
```

这段代码将读取数据集的前两行，从而避免加载不必要的数据块。

```plain
shape: (2, 19)
┌──────────┬────────────┬────────────┬───┬────────────┬────────────┬───────────┐
│ VendorID │ tpep_picku │ tpep_dropo │ … │ total_amou │ congestion │ airport_f │
│ ---      │ p_datetime │ ff_datetim │   │ nt         │ _surcharge │ ee        │
│ i64      │ ---        │ …          │   │ ---        │ ---        │ ---       │
│          │ datetime[n │ ---        │   │ f64        │ f64        │ f64       │
│          │ s]         │ datetime[n │   │            │            │           │
│          │            │ s]         │   │            │            │           │
╞══════════╪════════════╪════════════╪═══╪════════════╪════════════╪═══════════╡
│ 1        │ 2022-01-01 │ 2022-01-01 │ … │ 21.95      │ 2.5        │ 0.0       │
│          │ 00:35:40   │ 00:53:29   │   │            │            │           │
│ 1        │ 2022-01-01 │ 2022-01-01 │ … │ 13.3       │ 0.0        │ 0.0       │
│          │ 00:33:43   │ 00:42:07   │   │            │            │           │
└──────────┴────────────┴────────────┴───┴────────────┴────────────┴───────────┘
```

此操作在扫描级别只获取数据的前两行，并收集成一个DataFrame返回。这些下推操作可以完全避免对不必要的数据执行后续的转换，从而达到优化的目的。

<h3 id="QWwCl">其他优化</h3>
其他一些优化更注重高效计算。在本节中，我们将创建一个小型的`LazyFrame`作为示例来说明这些优化。

```python
lazy_df = pl.LazyFrame({
    "foo": [1, 2, 3, 4, 5],
    "bar": [6, 7, 8, 9, 10]
})
```

<h4 id="tZNxK">**公共子计划消除**</h4>
其中一个优化是**公共子计划消除（Common Subplan Elimination）**。子计划或子树是在查询计划中执行的一组步骤。当查询计划中的多个子树使用某些操作或文件扫描时，Polars会缓存这些结果以便于重用。例如： 

```python
# 示例代码
lf = pl.scan_parquet("data/taxi/yellow_tripdata_*.parquet")
result = lf.select(pl.col("trip_distance")).filter(pl.col("trip_distance") > 10).collect()
```

在这种情况下，如果多个子树都需要对同一个文件进行扫描或执行相同的操作，Polars可以缓存这些操作的结果，避免重复计算，从而提高查询效率。

```python
common_subplan = lazy_df.with_columns(pl.col("foo") * 2)

# Utilizing the common subplan in two separate expressions
expr1 = common_subplan.filter(pl.col("foo") * 2 > 4)
expr2 = common_subplan.filter(pl.col("foo") * 2 < 8)

result = pl.concat([expr1, expr2])

result.show_graph(optimized=False)
result.show_graph()
```

![图17-5. 未优化的查询计划](https://cdn.nlark.com/yuque/0/2024/png/1310472/1729089676088-b54e2db6-b9e0-44e8-b82b-39451881ffc7.png)![图17-6. 优化后的查询计划](https://cdn.nlark.com/yuque/0/2024/png/1310472/1729089683083-191cdb4c-fa79-48b2-8f1f-37cd522f2c4b.png)

在上述代码中，你使用`pl.concat()`方法组合了共享相同子计划的表达式。图17-5显示了未经优化的查询计划，图17-6显示了优化后的版本。在优化版本中，可以看到文件只读取了一次，并且只选择了“foo”列，而在未优化的版本中，文件被读取了两次。之后再应用不同的过滤条件。

---

**<font style="color:#01B2BC;">注意</font>**

在许多情况下，贪婪API实际上在底层调用了惰性API，并立即收集结果。这使得查询规划器仍然可以在查询内部进行优化。此外，这对维护者来说也更容易，因为贪婪API的方法只是惰性API的一个薄封装，从而避免了代码重复。

---

<h4 id="HdH0k">另一个优化：`with_columns`的聚合</h4>
当你连续多次调用`with_columns`时，Polars会尝试减少调用次数，并移除那些从未使用的调用。每个单独的`with_columns`调用都必须顺序执行，如果它们可以并行执行，这种顺序执行会成为性能瓶颈。

以下查询示例：

```python
df = (
    df.lazy()
    .with_columns(weight_per_cm=pl.col("weight_kg") / pl.col("length_cm"))
    .with_columns(weight_kg_average=pl.lit(0))
    .with_columns(length_m=pl.col("length_cm") / 100)
    .with_columns(weight_kg_average=pl.col("weight_kg").mean())
)
```

经过优化后，可以减少并优化为以下查询： 

```python
df = df.lazy().with_columns(
    weight_per_cm=pl.col("weight_kg") / pl.col("length_cm"),
    weight_kg_average=pl.col("weight_kg").mean(),
    length_m=pl.col("length_cm") / 100,
)
```

注意，`height_mean`列不再被添加两次，并且`with_columns`调用被合并为一个，这样可以进行并行化。

<h2 id="YgieL">Polars的性能分析</h2>
Polars的惰性API内置了用于性能分析的工具。在优化Polars查询的性能时，虽然可以在贪婪API中记录每个查询步骤的耗时，但在惰性API中无法这样做。这是因为惰性API在你对`LazyFrame`调用`.collect()`之前实际上并不执行查询，之后每个步骤会一次性执行。为了比较构成惰性API查询的不同操作的性能，可以使用`profile()`方法。

让我们测试一下这个方法，并对一个大数据集应用一些转换，以创建一个包含多个节点的查询计划。为此，你可以使用纽约市的黄色出租车行程数据。

```python
lf = pl.scan_parquet("data/taxi/yellow_tripdata_*.parquet")
lf = lf.filter(pl.col("trip_distance") > 10)
lf = lf.select(pl.col("VendorID"), pl.col("trip_distance"), pl.col("total_amount"))
lf = lf.group_by("VendorID").agg(
    pl.col("trip_distance").sum().alias("total_distance"),
    pl.col("total_amount").sum().alias("total_amount")
)
lf = lf.sort("total_distance", descending=True)

lf.show_graph()

```

![图17-7. 出租车数据集的查询计划](https://cdn.nlark.com/yuque/0/2024/png/1310472/1729089892689-782c6259-95e1-40e0-bfd4-03addda6e6a5.png)

现在你有了一个查询计划，如图17-7所示，你可以对其进行性能分析：

```python
lf.profile()
```

```plain
(shape: (4, 3)
 ┌──────────┬────────────────┬──────────────┐
 │ VendorID │ total_distance │ total_amount │
 │ ---      │ ---            │ ---          │
 │ i64      │ f64            │ f64          │
 ╞══════════╪════════════════╪══════════════╡
 │ 2        │ 1.3752e8       │ 1.6152e8     │
 │ 1        │ 1.3095e7       │ 5.2274e7     │
 │ 6        │ 347579.41      │ 1.3881e6     │
 │ 5        │ 1956.44        │ 8702.21      │
 └──────────┴────────────────┴──────────────┘,
 shape: (5, 3)
 ┌───────────────────────┬────────┬────────┐
 │ node                  │ start  │ end    │
 │ ---                   │ ---    │ ---    │
 │ str                   │ u64    │ u64    │
 ╞═══════════════════════╪════════╪════════╡
 │ optimization          │ 0      │ 35     │
 │ parquet(data/taxi/ye… │ 35     │ 268907 │
 │ simple-projection(Ve… │ 268917 │ 268925 │
 │ group_by_partitioned… │ 268932 │ 298631 │
 │ sort(total_distance)  │ 298642 │ 298795 │
 └───────────────────────┴────────┴────────┘)
```

使用`profile()`会返回一个包含结果的元组，就像`collect()`那样，但还会额外提供一个包含性能分析信息的DataFrame。这个DataFrame包含查询计划中每个节点的开始和结束时间（以微秒为单位）。通过这种方式，你可以看到哪些节点耗时最多，以及哪些是查询中的瓶颈。在这个示例中，可以看到`parquet()`节点耗时最多，这是预料之中的，因为它需要从磁盘读取数据。



为了更直观地查看哪些节点耗时最多，可以使用内置功能将其转换为图表：

```python
lf.profile(show_plot=True, figsize=(15,5))
```

```plain
(shape: (4, 3)
 ┌──────────┬────────────────┬──────────────┐
 │ VendorID │ total_distance │ total_amount │
 │ ---      │ ---            │ ---          │
 │ i64      │ f64            │ f64          │
 ╞══════════╪════════════════╪══════════════╡
 │ 2        │ 1.3752e8       │ 1.6152e8     │
 │ 1        │ 1.3095e7       │ 5.2274e7     │
 │ 6        │ 347579.41      │ 1.3881e6     │
 │ 5        │ 1956.44        │ 8702.21      │
 └──────────┴────────────────┴──────────────┘,
 shape: (5, 3)
 ┌───────────────────────┬────────┬────────┐
 │ node                  │ start  │ end    │
 │ ---                   │ ---    │ ---    │
 │ str                   │ u64    │ u64    │
 ╞═══════════════════════╪════════╪════════╡
 │ optimization          │ 0      │ 3      │
 │ parquet(data/taxi/ye… │ 3      │ 281276 │
 │ simple-projection(Ve… │ 281276 │ 281278 │
 │ group_by_partitioned… │ 281281 │ 309202 │
 │ sort(total_distance)  │ 309208 │ 309340 │
 └───────────────────────┴────────┴────────┘)
```

![图17-8. 出租车数据集查询的性能分析图](https://cdn.nlark.com/yuque/0/2024/png/1310472/1729090023995-d0dd994f-0728-47b5-a28c-90f054fb985e.png)



这将显示一个图表，如图17-8所示，图表中x轴表示查询计划中的节点，y轴表示执行这些节点所用的时间，执行顺序从上到下。可以通过提供`figsize`参数来调整图的大小，`figsize`是一个`tuple[int, int]`，表示图的宽度和高度（以英寸为单位）。

<h2 id="ctYU7">Polars中的测试</h2>
Polars有内置的测试函数，可以用来测试代码库。由于这些函数默认不导入，以保持库的高性能，它们有些不太显眼。

<h3 id="LFKbr">比较DataFrame和Series</h3>
可以像这样导入这四个基本函数：

```python
import polars as pl
from polars.testing import (
assert_series_equal,
assert_frame_equal,
assert_series_not_equal,
assert_frame_not_equal
)
```

这些函数用于比较两个Series或DataFrames，如果它们相等（或不相等，取决于函数的用途），则会引发错误。

```python
df1 = pl.DataFrame({
    'a': [1.0, 2.0, 3.0, 4.0],
})

df2 = pl.DataFrame({
    'a': [1.001, 2.0, 3.0, 4.0],
})

assert_frame_equal(df1, df2)
```

这种精确检查并不总是所需的结果。有时，足够接近的结果就可以接受。为此，这些方法中有一些可调参数，如表17-1所示。

_表17-1. 测试参数的使用_

| 参数 | 默认值 | 描述 |
| --- | --- | --- |
| `check_row_order` | True | 要求行顺序完全匹配。 |
| `check_column_order` | True | 要求列顺序完全匹配。 |
| `check_dtypes` | True | 要求数据类型完全匹配。 |
| `check_exact` | True | 要求浮点值完全匹配。如果设置为False，当值在容差范围内时被视为相等（参见`rtol`和`atol`）。这只影响浮点类型的列。 |
| `rtol` | 1e-5 | 用于不精确检查的相对容差。仅在`check_exact`为False时适用。 |
| `atol` | 1e-8 | 用于不精确检查的绝对容差。仅在`check_exact`为False时适用。 |
| `categorical_as_str` | False | 将分类列转换为字符串进行比较。启用此选项有助于比较没有共享相同字符串缓存的列，因为物理编码可能不匹配。 |


虽然`check_*`参数比较容易理解，但容差阈值需要进一步解释。`rtol`和`atol`参数用于确定两个浮点数有多接近才能被视为相等。

+ `rtol`参数是相对容差，意味着它依赖于被比较值的大小，并表示两个值之间的最大允许差异（以第二个值的分数表示）。其公式如下：

$ abs(a-b)\leq rtol^*abs(b)
\\\ $

`atol`参数是绝对容差，即设置两个值之间差异的固定值。将其分解为公式时，显示如下：

$ abs(a-b) \leq atol
\\\ $

现在，让我们看看这个参数在本节开头使用的框架上的效果，这些框架存在0.001的轻微不等。

```python
assert_frame_equal(df1, df2, rtol=0.01)
print("The frames are equal.")
```

```plain
The frames are equal.
```

这不会引发错误，因为这些值在彼此的0.01相对容差范围内。这在处理浮点数时尤其有用，因为由于其近似特性，可能会出现小的舍入误差。

---

`**<font style="color:#01B2BC;">from_repr()</font>**`**<font style="color:#01B2BC;">的优势</font>**

为了使单元测试中的框架初始化更具可读性，你可以使用`from_repr()`方法，即“从（字符串）表示”生成DataFrame。此方法将DataFrame的字符串表示转换为DataFrame，这为你提供了一种更可读的方式来保存预期的DataFrame，使你更容易查看测试的内容。

你可以粘贴字符串表示（可以选择不包括形状信息`shape(x,y)`），然后使用`from_repr()`方法将其转换为DataFrame，如下所示：

```python
result = pl.DataFrame({
    "a": [1, 3],
    "b": [2, 4]
}).cast(pl.Schema({"a": pl.Int8, "b": pl.Int8}))

expected = pl.from_repr(
    """
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ i8  ┆ i8  │
╞═════╪═════╡
│ 1   ┆ 2   │
│ 3   ┆ 4   │
└─────┴─────┘
    """
)

assert_frame_equal(result, expected)
print("Frames are equal!")
```

```plain
Frames are equal!
```

对于较大的框架，不推荐使用这种方法，因为它会降低代码的可读性，但对于较小的框架，这可以提供很大的帮助。

<h2 id="SsmMz">常见的反模式</h2>
Polars旨在处理执行细节，让你专注于想要做的事情。这意味着它会为你运行最佳的查询计划，而你不必担心内存管理或并行化等实现细节。然而，仍然有一些操作会减慢查询速度或降低效率。在本节中，我们将讨论在使用Polars时应避免的一些常见反模式。

<h4 id="KQwsv">使用方括号选择列</h4>
尽管Polars支持使用方括号表示法进行切片和索引（`df[...]`），但这主要是为了兼容其他库。我们不推荐使用这种语法，因为它的效率低于使用`col()`方法。如果使用`col()`并将其转换为表达式，Polars的优化器可以处理、并行化和优化它（尤其是在使用惰性API时）。请参考第9章，以将方括号表示法替换为其他方法。

一般来说，如果你在考虑DataFrame中某列的位置，而不是使用API来定义要操作的列，说明你可能走错了方向。

<h4 id="gIMZy">滥用`collect()`</h4>
惰性API旨在尽可能高效地工作：它收集你要执行的所有操作，利用尽可能多的数据知识优化查询计划，然后执行查询。当你调用`collect()`时，它会执行查询计划并从磁盘读取数据。然而，如果多次重复使用同一个`LazyFrame`，你可以通过不在每次使用数据时都调用`collect()`来节省大量时间，因为每次都需要从头开始读取和执行数据。如果你想获取数据的两个不同子集，比如机器学习模型中的训练集和测试集，或者在以下情况下将数据分成两个不同的供应商：

```python
%%time
lf = pl.scan_parquet("data/taxi/yellow_tripdata_*.parquet")
vendor0 = lf.filter(pl.col("VendorID") == 0).collect()
vendor1 = lf.filter(pl.col("VendorID") == 1).collect()
```

```plain
CPU times: user 21.8 s, sys: 20 s, total: 41.8 s
Wall time: 7.14 s
```

这段代码将从磁盘读取数据两次：第一次用于第一个子集，第二次用于第二个子集。然而，更有效的方法是一次性加载数据，然后过滤两次：

```python
%%time
lf = pl.scan_parquet("data/taxi/yellow_tripdata_*.parquet")
df = lf.filter(pl.col("VendorID").is_in([0,1])).collect()
vendor0 = df.filter(pl.col("VendorID") == 0)
vendor1 = df.filter(pl.col("VendorID") == 1)
```

```plain
CPU times: user 20.7 s, sys: 11.1 s, total: 31.8 s
Wall time: 4.92 s
```

这导致运行时间减少了31%。这个示例主要是IO绑定，但在更复杂的问题中，这种优化可能会带来更大的加速。

然而，另一种极端情况是过度使用`collect()`。当你在`LazyFrame`上不断调用`collect()`时，你会失去惰性API的所有好处：它在执行太多工作，因为无法应用优化。在这种情况下，你不如直接使用贪婪API。

要注意何时调用`collect()`，只有在实际需要数据在内存中时才调用。

<h4 id="eqdga">在Polars查询中使用Python代码</h4>
Polars旨在尽可能多地在Rust中运行，而Rust是一种编译语言，设计用于安全地并行运行，因此比Python快得多。当你在Polars查询中使用Python代码时，你迫使Polars切换到Python，从而减慢查询速度。

尽管`.agg()`和`.map_*()`方法旨在与Python代码一起使用，但你仍然应该谨慎使用它们。始终查阅API文档，以查看是否有方法可以连接在一起，以在不使用Python代码的情况下实现相同的结果。此外，你可以随时在Polars的Discord服务器上寻求Polars社区的帮助。如果你在API中找不到所需的内容，可以在Rust中编写自己的用户定义函数（UDF），这将比Python代码快得多。如果没有其他选择（例如，你使用的是来自其他库的Python函数），你仍然可以使用Python代码，但这应作为最后的手段。

<h2 id="XkHo5">全书小结</h2>
在本章的最后，你了解到：

+ Polars建立在Apache Arrow之上，提供了针对现代硬件优化的列式内存格式。
+ 多线程计算和SIMD操作使Polars能够充分利用现代硬件。
+ Polars中的字符串数据类型经过优化以提高性能，使用视图布局和短字符串的内联存储。
+ Polars采用多种查询优化技术，包括投影下推、谓词下推和切片下推。
+ Polars中的流式模式按块处理数据，块大小可根据可用线程和数据集特征进行配置。
+ Polars提供内置性能分析工具，以帮助识别查询中的性能瓶颈。
+ 该库包括用于比较DataFrames和Series的测试函数，支持精确和近似比较的选项。
+ 应避免常见反模式，包括使用方括号选择列、在惰性API中误用`collect()`以及在Polars查询中过度使用Python代码。

这本书到此结束！你现在具备了充分利用Polars进行数据处理所需的知识。如果你还有问题，可以通过Stack Overflow、Polars GitHub库或Polars Discord服务器随时联系Polars社区。

