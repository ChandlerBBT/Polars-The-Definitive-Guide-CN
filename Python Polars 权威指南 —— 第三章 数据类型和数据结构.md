

既然你已经大致了解了流行的数据框库与 Polars 之间的区别，是时候专注于 Polars 的工作方式了。

数据有许多不同的形式和大小，这些数据都需要存储在内存中以便进行处理。为了适应你将要处理的所有数据，Polars 实现了 **Arrow 内存规范**，这允许使用一系列数据类型。在本章中，你将了解这些数据类型，我们还会详细解释一些不那么直观的数据类型。

首先，我们将介绍 **Apache Arrow**，这是 Polars 用来管理内存数据存储的库。接下来，我们将讨论可用的不同数据类型。我们会详细讲解一些不太直观的数据类型。最后，我们将介绍 Polars 用来处理所有这些数据类型的结构。

---

<h1 id="s4k4I">**Arrow 数据类型**</h1>
为了高效存储数据，Polars 基于 **Apache Arrow** 项目。

Arrow 自我描述为“一种用于内存分析的跨语言开发平台”。它定义了一种“语言无关的列式内存格式，用于扁平和分层数据，并为在现代硬件（如 CPU 和 GPU）上进行高效分析操作而组织。”Arrow 开箱即用地带来了几个优势。

首先，它使用了**列式格式**。这种格式使得数据相邻的顺序访问或扫描变得更加容易，从而优化了在连续数据块中读取大量数据的过程。这样你可以将数据存储在大块的顺序数据中，并进行连续读取。

此外，这种连续的列式布局是**向量化友好的**。它允许你使用现代的**单指令、多数据（SIMD）操作**，从而可以在多个数据点上同时执行相同的操作。

为了更好地说明这些优势，我们将使用文件柜的类比来介绍。

![Figure 3-1 描述了 Arrow 内存缓冲区及其在计算中的优势。这张图可能展示了 Arrow 如何将数据存储在列式内存中，使得数据能够更高效地顺序访问和进行并行处理。通过列式存储，Arrow 能够在现代硬件（如 CPU 和 GPU）上利用向量化和 SIMD 技术进行加速，从而显著提升大规模数据处理的性能。](https://cdn.nlark.com/yuque/0/2024/png/1310472/1728538980405-682dc99a-6d3e-4872-8461-701447de8a91.png)



这些优势可以通过使用文件柜的类比来很好地解释，在文件柜中你存储销售档案。在基于行的格式中，文件柜的每个抽屉都包含与单笔销售相关的所有数据。一个抽屉包含销售给谁的物品、售出的物品、销售价格以及销售发生的时间。如果你总是需要挖掘所有销售的信息，那么将这些信息捆绑在一起是很实用的。

然而，在分析查询中，更常见的是查找销售档案的特定部分，而不是全部信息。举个例子：你想制作一份包含你五个最大客户的报告。这样你就知道应该多关注哪些客户。如果你的文件柜是按行排列的，每个抽屉都包含一个客户的全部档案，那么你需要打开每个抽屉才能查看销售总价，并确定这些档案属于哪个客户。

当我们将文件柜按列方式排列时，每个抽屉只包含所有客户的一个数据类别。这意味着其中一个抽屉将包含所有销售价格。

顺序读取意味着你可以从抽屉中的第一个文件开始，然后继续读取下一个，直到到达抽屉的末尾。这加快了处理速度，因为你不需要关闭一个抽屉，打开另一个，寻找相关文件。从价格抽屉中，你可以确定最大的客户档案ID。要知道这些客户是谁，你可以转到姓名抽屉，并查看文件，直到找到与刚才找到的5个客户档案ID相匹配的5个姓名。这意味着你只需要打开2个抽屉，而不是打开所有的抽屉，这为你节省了大量时间和麻烦。

由于这种列式格式，Arrow 提供了 O(1)，即**常数时间**的随机访问。这意味着无论数据集变得多大，访问任何单个数据所需的时间都保持不变。如果我们回到文件柜的类比，这看起来像是我们确切地知道每条信息存储在哪里。不仅知道哪个抽屉，还知道抽屉中的具体位置。这意味着你不需要搜索整个抽屉，直到找到相关数据。对于需要访问大数据集中特定数据点的操作，这是一个显著的性能优势。

Arrow 支持多种流行语言的实现。截至撰写本文时，支持的语言包括：C/GLib、C++、C#、Go、Java、JavaScript、Julia、MATLAB、Python、R、Ruby 和 Rust。不同语言中的实现程度可能有所不同：例如，`Float16` 数据类型并未在每种语言中实现。

---

<font style="color:#ECAA04;">注意：</font>

`Float32` 数据类型是一种 32 位浮点数格式，也被称为单精度浮点数。这比 16 位半精度格式更常见，并在范围和精度之间提供了良好的平衡。

这 32 位包含以下信息：

+ 第 1 位表示符号位（0 表示正，1 表示负）
+ 第 2-9 位表示指数，用来乘以尾数。
+ 第 10-32 位表示尾数，二进制表示中隐含了一个前导的 1。

计算 `Float32` 值的公式如下：

$ (-1){sign} \times (1 + fraction) \times 2{(exponent - bias)}
\\\ $

对于 `Float32`，偏置（bias）是一个常数值 127。这意味着实际的指数值可以通过将这个偏置从二进制指数表示中减去来获得。使用偏置的原因是为了确保浮点数能够表示非常大的数和非常小的数。



示例：考虑下面这个浮点数的位表示：

```plain
0 10000010 10100000000000000000000
```

+ **0** 表示浮点数为正。
+ **10000010** 是二进制的指数，表示十进制的 130。
+ **10100000000000000000000** 是二进制中的尾数部分。通过在这些二进制位前添加一个隐含的 1（对于规范化数），并将其解读为以下内容：1（隐含的前导 1）加上 1 ($ \times) 2^{-1} $（第一位，表示 0.5）加上 $ 0 (\times) 2^{-2} $（第二位，忽略，因为它是 0）加上 $ 1 (\times) 2^{-3} $（第三位，表示 0.125）。后面的位为零，不影响值。因此，尾数等于：$ 1 + 0.5 + 0.125 = 1.625 $

将这些值代入公式中：

+ $ \text{Float} = (-1)0 \times (1 + 0.5 + 0.125) \times 2{(130 - 127)} $
+ $ \text{Float} = 1 \times 1.625 \times 8 $
+ $ \text{Float} = 13 $

---



不同语言的实现允许你使用共享的可变数据集而无需进行序列化/反序列化。通常，不同的语言在内存中位表示数据的方式有所不同。这意味着为了在不同语言之间匹配数据，你首先必须将数据从一种格式反序列化，然后再序列化为另一种格式。这个转换步骤需要时间。Arrow 通过允许所有支持的实现和语言以统一的方式与相同的数据集交互来避免这一点。这种共享可变数据集的方式称为**进程间通信（IPC）**。

Polars 的核心是用 Rust 编写的，以充分利用该语言的性能。使用 Arrow Rust 实现，Polars 实现了如**表 3-1** 所示的数据类型。某些数据类型有多个不同位大小的版本。这允许你存储在范围内的数据，同时占用较少的内存。



表 3-1：Polars 支持的数据类型

| 组别 | 类型 | 详细信息 | 范围 |
| --- | --- | --- | --- |
| **基类** | `DataType` | 所有 Polars 数据类型的基类 | - |
| **数值类型** | `Decimal` | 128 位十进制类型，带可选精度和非负刻度 | 可以精确表示 38 位有效数字 |
|  | `Float32` | 32 位浮点数类型 | -3.4e+38 到 3.4e+38 |
|  | `Float64` | 64 位浮点数类型 | -1.7e+308 到 1.7e+308 |
|  | `Int8` | 8 位有符号整数类型 | -128 到 128 |
|  | `Int16` | 16 位有符号整数类型 | -32,768 到 32,767 |
|  | `Int32` | 32 位有符号整数类型 | -2,147,483,648 到 2,147,483,647 |
|  | `Int64` | 64 位有符号整数类型 | -9,223,372,036,854,775,808 到 9,223,372,036,854,775,807 |
|  | `UInt8` | 8 位无符号整数类型 | 0 到 255 |
|  | `UInt16` | 16 位无符号整数类型 | 0 到 65,535 |
|  | `UInt32` | 32 位无符号整数类型 | 0 到 4,294,967,295 |
|  | `UInt64` | 64 位无符号整数类型 | 0 到 1.8446744e+19 |
| **时间类型** | `Date` | 日历日期类型。使用 Arrow 的 date32 数据类型 | -5877641-06-24 到 5879610-09-09 |
|  | `Datetime` | 日历日期和时间类型。自 UNIX 纪元的精确时间戳 | - |
|  | `Duration` | 时间持续时间/时间差类型 | - |
|  | `Time` | 一天中的时间类型 | - |
| **嵌套类型** | `<font style="color:rgb(61, 59, 73);background-color:rgb(238, 242, 246);">Array(*args, **kwargs)</font>` | 固定长度的列表类型 | - |
|  | `<font style="color:rgb(61, 59, 73);">List(*args, **kwargs)</font>` | 可变长度的列表类型 | - |
|  | <font style="color:rgb(61, 59, 73);background-color:rgb(238, 242, 246);">Struct(*args, **kwargs)</font> | 结构类型，包含多个字段 | - |
| **其他类型** | `Boolean` | 布尔类型，占用 1 位存储空间 | True 或 False |
|  | `Binary` | 可变长度的字节类型 | - |
|  | `Categorical` | 字符串集合的分类编码，可以更高效地使用内存 | - |
|  | `Null` | 表示 Null / None 值的类型 | - |
|  | `Object` | 包装任意 Python 对象的类型 | - |
|  | `String` | UTF-8 编码的可变长度字符串类型 | - |
|  | `Unknown` | 表示无法静态确定的数据类型 | - |


此表格总结了 Polars 数据类型的不同类别、详细信息和数值范围。

---

**<font style="color:#ECAA04;">注意</font>**

在使用 Python 数据创建 DataFrame 时，可能需要添加任意的 Python 数据。例如，在 DataFrame 中你可能希望存储一个机器学习模型。在这种情况下，使用 `Object` 数据类型。该数据类型允许将任意的 Python 对象放入 DataFrame 中。

缺点是，这些数据无法使用正常的函数处理。因为 Polars 不使用 Python 来查看数据表示形式，所以没有进行任何优化。这意味着 `Object` 列在 DataFrame 中可以被视为一个乘客，参与连接操作，但不参与优化的计算。

通常，当数据可以用其他数据类型表示时，建议不要使用 `Object` 数据类型，但有时可能会有使用场景。

---

**<font style="color:#ECAA04;">注意</font>**

在文档中，你可能会发现 `Unknown` 数据类型。`Unknown` 数据类型仅作为占位符在内部使用，不应在你的代码中使用。

<h3 id="cj5cl"></h3>
<h2 id="J9bnM">嵌套数据类型(<font style="color:rgb(61, 59, 73);">Nested Data Types)</font></h2>
你可能已经注意到嵌套数据类型具有参数。这是因为嵌套数据类型是一种特殊的数据类型。当一种数据类型可以包含其他数据类型时，它就被称为嵌套类型。这些参数定义了该类型可以包含的元素数量，以及其包含的数据类型。Polars有三种嵌套类型：`Array`、`List`和`Struct`。

**Array** 类似于Numpy的`ndarray`。它是一个相同数据类型元素的集合。此外，数组的长度在所有行中必须相同。`Array`类型的参数是数组的宽度以及数组中元素的数据类型。

```python
import polars as pl

array_df = pl.DataFrame(
    [
        pl.Series("array_1", [[1, 3], [2, 5]]),
        pl.Series("array_2", [[1, 7, 3], [8, 1, 0]]),
    ],
    schema={
        "array_1": pl.Array(width=2, inner=pl.Int64),
        "array_2": pl.Array(width=3, inner=pl.Int64),
    }
)
array_df
```

```plain
shape: (2, 2)
┌───────────────┬───────────────┐
│ array_1       │ array_2       │
│ ---           │ ---           │
│ array[i64, 2] │ array[i64, 3] │
╞═══════════════╪═══════════════╡
│ [1, 3]        │ [1, 7, 3]     │
│ [2, 5]        │ [8, 1, 0]     │
└───────────────┴───────────────┘
```



**List** 类似于`Array`，它是相同数据类型元素的集合。但与`Array`不同的是，`List`不要求每行的长度相同。请注意，它与Python中的`list`不同，Python中的`list`可以包含不同的数据类型。你可以通过将数据类型设置为`Object`来在列中存储Python的列表。`List`类型唯一的参数是它包含的数据类型。

```python
list_df = pl.DataFrame(
    {
        "integer_lists": [[1, 2], [3, 4]],
        "float_lists": [[1.0, 2.0], [3.0, 4.0]],
    }
)
list_df
```

```plain
shape: (2, 2)
┌───────────────┬─────────────┐
│ integer_lists │ float_lists │
│ ---           │ ---         │
│ list[i64]     │ list[f64]   │
╞═══════════════╪═════════════╡
│ [1, 2]        │ [1.0, 2.0]  │
│ [3, 4]        │ [3.0, 4.0]  │
└───────────────┴─────────────┘
```



最后，`Struct`是Polars中处理多列的惯用方法。Polars通过表达式转换数据。我们将在**第五章**中深入讨论表达式，目前你只需要知道表达式是将输入`Series`映射到输出的函数（类型为`Series: fn(Series) -> Series`）。为了允许表达式使用多列作为输入，可以使用`Struct`数据类型将多个列表示为单个列。这样，要求多列作为输入的表达式仍然可以满足只接收`Series`作为输入的要求。这意味着`Struct`可以包含不同的数据类型，只要它们在行上匹配即可。`Struct`可以使用Python字典来构建，如下所示：

```python
rating_series = pl.Series(
    "ratings",
    [
        {"Movie": "Cars", "Theatre": "NE", "Avg_Rating": 4.5},
        {"Movie": "Toy Story", "Theatre": "ME", "Avg_Rating": 4.9},
    ],
)
rating_series
```

```plain
shape: (2,)
Series: 'ratings' [struct[3]]
[
	{"Cars","NE",4.5}
	{"Toy Story","ME",4.9}
]
```



<h2 id="fVItD">缺失值(<font style="color:rgb(61, 59, 73);">Missing Values）</font></h2>
在Polars中，缺失数据始终使用`null`表示。这个`null`适用于所有数据类型，包括数值型数据。有关缺失值的信息存储在Arrow数组的元数据中。

此外，是否缺失的值存储在其**有效性位图(**_**<font style="color:rgb(61, 59, 73);">validity bitmap</font>**__<font style="color:rgb(61, 59, 73);">) </font>_中，这是一个位，如果值存在则设置为1，如果值缺失则设置为0。这允许你快速检查列中有多少值是缺失的，可以使用诸如`null_count()`和`is_null()`等方法。

为了演示这一点，我们将创建一个包含一些缺失值的DataFrame：

```python
df = pl.DataFrame(
    {
        "value": [None, 2, 3, 4, None, None, 7, 8, 9, None],
    }
)
print(df)
```

```plain
shape: (10, 1)
┌───────┐
│ value │
│ ---   │
│ i64   │
╞═══════╡
│ null  │
│ 2     │
│ 3     │
│ 4     │
│ null  │
│ null  │
│ 7     │
│ 8     │
│ 9     │
│ null  │
└───────┘
```



你可以使用`fill_null()`方法以多种方式填充缺失数据：

+ 使用单个值
+ 使用填充策略
+ 使用表达式
+ 使用插值法

以下示例展示了如何用单个`pl.lit(...)`值进行填充：

```python
print(
    df
    .with_columns(
        pl.col("value")
        .fill_null(-1)
        .alias("filled_with_lit")
    )
)
```

```plain
shape: (10, 2)
┌───────┬─────────────────┐
│ value │ filled_with_lit │
│ ---   │ ---             │
│ i64   │ i64             │
╞═══════╪═════════════════╡
│ null  │ -1              │
│ 2     │ 2               │
│ 3     │ 3               │
│ 4     │ 4               │
│ null  │ -1              │
│ null  │ -1              │
│ 7     │ 7               │
│ 8     │ 8               │
│ 9     │ 9               │
│ null  │ -1              │
└───────┴─────────────────┘
```



第二种选择是使用填充策略。**填充策略**允许你从以下列表中选择一种插补方法：

+ `None`：不填充缺失值。
+ `forward`：用前一个非缺失值填充。
+ `backward`：用下一个非缺失值填充。
+ `min`：用该列的最小值填充。
+ `max`：用该列的最大值填充。
+ `mean`：用该列的平均值填充。注意，这里的平均值会被转换为该列的数据类型，如果是整型数据，逗号后的小数部分将被截断。
+ `zero`：填充为0。
+ `one`：填充为1。

在下面的示例中，你将看到所有这些策略的应用：

```python
print(
    df
    .with_columns(
        pl.col("value")
        .fill_null(strategy="forward")
        .alias("forward"),
        pl.col("value")
        .fill_null(strategy="backward")
        .alias("backward"),
        pl.col("value")
        .fill_null(strategy="min")
        .alias("min"),
        pl.col("value")
        .fill_null(strategy="max")
        .alias("max"),
        pl.col("value")
        .fill_null(strategy="mean")
        .alias("mean"),
        pl.col("value")
        .fill_null(strategy="zero")
        .alias("zero"),
        pl.col("value")
        .fill_null(strategy="one")
        .alias("one")
    )
)
```

```plain
shape: (10, 8)
┌───────┬─────────┬──────────┬─────┬─────┬──────┬──────┬─────┐
│ value │ forward │ backward │ min │ max │ mean │ zero │ one │
│ ---   │ ---     │ ---      │ --- │ --- │ ---  │ ---  │ --- │
│ i64   │ i64     │ i64      │ i64 │ i64 │ i64  │ i64  │ i64 │
╞═══════╪═════════╪══════════╪═════╪═════╪══════╪══════╪═════╡
│ null  │ null    │ 2        │ 2   │ 9   │ 5    │ 0    │ 1   │
│ 2     │ 2       │ 2        │ 2   │ 2   │ 2    │ 2    │ 2   │
│ 3     │ 3       │ 3        │ 3   │ 3   │ 3    │ 3    │ 3   │
│ 4     │ 4       │ 4        │ 4   │ 4   │ 4    │ 4    │ 4   │
│ null  │ 4       │ 7        │ 2   │ 9   │ 5    │ 0    │ 1   │
│ null  │ 4       │ 7        │ 2   │ 9   │ 5    │ 0    │ 1   │
│ 7     │ 7       │ 7        │ 7   │ 7   │ 7    │ 7    │ 7   │
│ 8     │ 8       │ 8        │ 8   │ 8   │ 8    │ 8    │ 8   │
│ 9     │ 9       │ 9        │ 9   │ 9   │ 9    │ 9    │ 9   │
│ null  │ 9       │ null     │ 2   │ 9   │ 5    │ 0    │ 1   │
└───────┴─────────┴──────────┴─────┴─────┴──────┴──────┴─────┘
```



第三种填充缺失值的方式是使用表达式，例如：

```python
pl.col("value").mean()
```

```python
print(
    df
    .with_columns(
        pl.col("value")
        .fill_null(pl.col("value").mean())
        .alias("expression_mean")
    )
)
```

```plain
shape: (10, 2)
┌───────┬─────────────────┐
│ value │ expression_mean │
│ ---   │ ---             │
│ i64   │ f64             │
╞═══════╪═════════════════╡
│ null  │ 5.5             │
│ 2     │ 2.0             │
│ 3     │ 3.0             │
│ 4     │ 4.0             │
│ null  │ 5.5             │
│ null  │ 5.5             │
│ 7     │ 7.0             │
│ 8     │ 8.0             │
│ 9     │ 9.0             │
│ null  │ 5.5             │
└───────┴─────────────────┘
```



第四种也是最后一种方式是使用插值法，如：

```python
df.interpolate()
```

```python
print(
    df.interpolate()
)
```

```plain
shape: (10, 1)
┌───────┐
│ value │
│ ---   │
│ f64   │
╞═══════╡
│ null  │
│ 2.0   │
│ 3.0   │
│ 4.0   │
│ 5.0   │
│ 6.0   │
│ 7.0   │
│ 8.0   │
│ 9.0   │
│ null  │
└───────┘
```



---

**<font style="color:#ECAA04;">警告</font>**

`NaN`（表示“非数字”）的值在Polars中不被视为缺失数据。这些值用于`Float`数据类型以表示某个运算的结果不是数字。

因此，`NaN`值不会在诸如`null_count()`或`fill_null()`这样的函数中被视为`null`值。可以使用`is_nan()`和`fill_nan()`函数来处理这些值。

---



<h1 id="mxC5n">Series、DataFrames 和 LazyFrames</h1>
所有这些类型的数据都可以存储在 Series 或 DataFrame 中。一个 `Series` 是相同数据类型的单列数据。一个 `DataFrame` 是一种二维数据结构，它表示为具有行和列的表格数据。一个 DataFrame 内部表示为由相同长度的 `Series` 组成的集合。每个 `Series`（因此每个 DataFrame 中的列）内部表示为一个 `ChunkedArray`。

一个 `ChunkedArray` 是一个用于存储数据数组序列的容器类。使用 `ChunkedArray` 而不是将所有数据存储在单个数组中，允许进行多种优化，包括优化的内存管理。当你向一个 `ChunkedArray` 添加数据时，数据会被添加到现有对象中。这样 Polars 就不需要将数据复制到新数组，也不需要垃圾回收旧数组，从而节省了时间。此外，Polars 允许将数据分块，这些块可以单独并行地操作，以最大化性能。每个块都可以由不同的 CPU 核心处理，从而显著加快计算速度。

---

**<font style="color:#1DC0C9;">注释：</font>**

管理这些块优化了 Polars 处理数据的方式。`Rechunking` 是更改 `ChunkedArray` 的块大小的过程。在 Polars 中，`rechunking` 通常是指将所有数据放入一个块中。每个块中的数据在内存中是连续的。在急切评估的情况下，数据在读取后会被重新块化。这是因为默认假设用户打算对数据进行分析。通常同一个 DataFrame 会被多次查询，因此额外的时间用于重新块化是值得的。当使用惰性评估时，查询优化器决定何时进行重新块化。

通常，你不需要考虑这一点。只需要知道当你在操作中设置 `rechunk` 参数为 `True` 时，实际上有两个操作在发生。这一点在基准测试时需要考虑。

---

`LazyFrame` 是一种懒惰求值的 `DataFrame`。这意味着与 `DataFrame` 是一个包含内存中所有数据的对象不同，`LazyFrame` 并不包含实际数据。所有读取操作和对其应用的转换都不会立即求值，直到它们真正需要为止。在实际需要 `DataFrame` 之前，它仅仅是一个包含所有必要计算步骤的查询图。使用这个查询图提供了许多通过查询优化器进行优化的机会。

我们将在第 5 章深入探讨不同 API 的使用，其中包括 Lazy API。



<h1 id="vydWV">数据类型转换</h1>
`Series`的一个功能是`cast()`，它可以将数据类型从当前的类型转换为作为参数提供的另一种类型。假设在解析CSV文件后，所有数据的类型目前都是字符串。结合`DataFrame`的`estimated_size()`函数，我们可以估算一个`DataFrame`的内存占用量。

```python
string_df = pl.DataFrame({"id": ["10000", "20000", "30000"]})
print(string_df)
print(f"Estimated size: {string_df.estimated_size('b')} bytes")
```

```plain
shape: (3, 1)
┌───────┐
│ id    │
│ ---   │
│ str   │
├───────┤
│ 10000 │
│ 20000 │
│ 30000 │
└───────┘ 估算大小：15字节
```



但是你知道其中一列只包含数值类型的数据，这些数据可以更高效地存储。通过改变数据类型，代码如下所示：

```python
int_df = string_df.select(pl.col("id").cast(pl.UInt16))
print(int_df)
print(f"Estimated size: {int_df.estimated_size('b')} bytes")
```

```plain
shape: (3, 1)
┌───────┐
│ id    │
│ ---   │
│ u16   │
├───────┤
│ 10000 │
│ 20000 │
│ 30000 │
└───────┘ 估算大小：6字节
```



这个简单的`cast`操作，通过将数据转换为更合适的数据类型，使得内存使用量减少了超过60%！使用合适的数据类型可以带来显著的性能优势。

表格3-1展示了对于相关数据类型的每个范围。通过选择最小的适合的数据类型，可以优化内存使用。

在上面的例子中，使用了作为表达式的`cast`函数。你也可以在`DataFrame`或`LazyFrame`上使用它。在这种情况下，你可以一次性将多个列映射到一个数据类型，或者使用映射规则进行转换。映射规则可以是一个Python字典，描述每一列应转换为哪种数据类型。键可以是列名，或列选择器。以下是`cast()`函数的使用方式，首先是将所有列转换为同一种数据类型：

```python
df = pl.DataFrame(
{
    "id": [10000, 20000, 30000],
    "value": [1.0, 2.0, 3.0],
    "value2": ["1", "2", "3"],
}
)
df.cast(pl.UInt16)
```

```plain
shape: (3, 3)
┌───────┬────────┬────────┐
│ id    │ value  │ value2 │
│ ---   │ ---    │ ---    │
│ u16   │ u16    │ u16    │
├───────┼────────┼────────┤
│ 10000 │ 1      │ 1      │
│ 20000 │ 2      │ 2      │
│ 30000 │ 3      │ 3      │
└───────┴────────┴────────┘
```



或者使用映射来指定要转换的列：

```python
df.cast({"id": pl.UInt16, "value": pl.Float32, "value2": pl.UInt8})
```

```plain
shape: (3, 3)
┌───────┬────────┬────────┐
│ id    │ value  │ value2 │
│ ---   │ ---    │ ---    │
│ u16   │ f32    │ u8     │
├───────┼────────┼────────┤
│ 10000 │ 1.0    │ 1      │
│ 20000 │ 2.0    │ 2      │
│ 30000 │ 3.0    │ 3      │
└───────┴────────┴────────┘
```



你也可以将特定的数据类型转换为其他数据类型，如下所示：

```python
df.cast({pl.Float64: pl.Float32, pl.String: pl.UInt8})
```

```plain
shape: (3, 3)
┌───────┬────────┬────────┐
│ id    │ value  │ value2 │
│ ---   │ ---    │ ---    │
│ i64   │ f32    │ u8     │
├───────┼────────┼────────┤
│ 10000 │ 1.0    │ 1      │
│ 20000 │ 2.0    │ 2      │
│ 30000 │ 3.0    │ 3      │
└───────┴────────┴────────┘
```



最后，你还可以使用列选择器来转换列的数据类型：

---

```python
import polars.selectors as cs
df.cast({cs.numeric(): pl.UInt16})
```

```plain
shape: (3, 3)
┌───────┬────────┬────────┐
│ id    │ value  │ value2 │
│ ---   │ ---    │ ---    │
│ u16   │ u16    │ str    │
├───────┼────────┼────────┤
│ 10000 │ 1      │ 1      │
│ 20000 │ 2      │ 2      │
│ 30000 │ 3      │ 3      │
└───────┴────────┴────────┘
```

基础的类型转换并不总是神奇地起作用。在某些情况下，需要使用特殊方法，因为某些数据无法在没有额外信息的情况下被正确解析。一个例子是从`String`解析为`DateTime`。在第11章中，你将阅读到如何进行更高级的类型转换。



<h1 id="kjQ0P">结论</h1>
在本章中，你学习了以下内容：

+ Polars 底层使用的 Arrow 内存规范。
+ Polars 提供的数据存储的不同数据类型。
+ 某些数据类型提供了特有的操作，例如字符串、分类变量和与时间相关的数据类型。在第10章中，我们将更深入地探讨这些细节。
+ Polars 如何处理缺失数据。
+ Polars 提供的用于操作这些数据的结构：`Series`、`DataFrame` 和 `LazyFrames`。
+ 使用 `cast()` 函数改变数据类型。

这些知识可以用来填充我们的`DataFrame`。在下一章中，你将深入研究 Polars 提供的不同API，以处理这些数据。

